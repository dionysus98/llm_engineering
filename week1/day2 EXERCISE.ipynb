{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "PORT = 11434\n",
    "OLLAMA_API = \"http://localhost:\" + str(PORT) + \"/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Describe some of the business applications of Generative AI\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"model\": MODEL, \"messages\": messages, \"stream\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as images, videos, and text based on patterns learned from large datasets. This can be particularly useful for businesses that need to produce a high volume of content quickly, such as:\n",
      " * Social media management\n",
      " * Blogging and publishing\n",
      " * Advertising and marketing materials\n",
      "2. **Design and Prototyping**: Generative AI can assist in designing and prototyping products, architecture, and urban planning by generating 3D models, CAD designs, and other visualizations.\n",
      " * Architecture and interior design firms\n",
      " * Product design and engineering companies\n",
      " * Urban planning and city development agencies\n",
      "3. **Customer Service and Support**: Generative AI can be used to generate personalized responses to customer inquiries, freeing up human support agents to focus on more complex issues.\n",
      " * Customer service and support teams\n",
      " * Online retailers and e-commerce businesses\n",
      " * Financial institutions and banking services\n",
      "4. **Marketing and Advertising**: Generative AI can help create targeted advertising campaigns by generating personalized ads based on user behavior and preferences.\n",
      " * Ad agencies and marketing firms\n",
      " * E-commerce businesses and online retailers\n",
      " * Social media platforms and influencers\n",
      "5. **Healthcare and Medicine**: Generative AI can be used to analyze medical images, generate personalized treatment plans, and develop new medical treatments.\n",
      " * Medical research institutions and universities\n",
      " * Hospitals and healthcare providers\n",
      " * Pharmaceutical companies and biotech firms\n",
      "6. **Finance and Risk Management**: Generative AI can help analyze financial data, identify trends and patterns, and predict market fluctuations.\n",
      " * Investment banks and financial institutions\n",
      " * Hedge funds and private equity firms\n",
      " * Regulatory agencies and compliance teams\n",
      "7. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations by predicting demand, identifying bottlenecks, and suggesting improvements.\n",
      " * Supply chain management companies\n",
      " * Logistics and transportation providers\n",
      " * Manufacturing and production companies\n",
      "8. **Education and Training**: Generative AI can help create personalized learning experiences for students by generating customized educational content and assessing student progress.\n",
      " * Educational institutions and universities\n",
      " * Online course providers and training platforms\n",
      " * Corporate training departments\n",
      "9. **Virtual Reality (VR) and Augmented Reality (AR)**: Generative AI can be used to generate 3D models, environments, and objects for VR and AR experiences.\n",
      " * Gaming companies and developers\n",
      " * Film and animation studios\n",
      " * Architecture and design firms\n",
      "10. **Music and Audio Generation**: Generative AI can be used to create original music, audio tracks, and sound effects for film, television, and advertising applications.\n",
      " * Music production companies and composers\n",
      " * Sound design and audio post-production studios\n",
      " * Advertising agencies and creative directors\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources while also improving the efficiency of their content creation processes.\n",
      "\n",
      "2. **Customer Service Chatbots**: Generative AI-powered chatbots can be designed to provide 24/7 customer support, helping businesses respond to customer inquiries in a timely manner without the need for human intervention.\n",
      "\n",
      "3. **Product Description Generation**: Companies can use Generative AI to generate product descriptions that are more engaging and effective at driving sales. This can help businesses stand out from competitors and improve their conversion rates.\n",
      "\n",
      "4. **Music and Audio Production**: Generative AI can be used to create custom music tracks for videos, ads, or other marketing materials. It can also be used to create personalized audio experiences for customers.\n",
      "\n",
      "5. **Data Analysis and Visualization**: Generative AI can be used to analyze large datasets and generate insights that would be difficult or impossible to obtain through traditional methods.\n",
      "\n",
      "6. **Digital Marketing**: Generative AI can help businesses automate their digital marketing efforts, such as generating ad copy, creating social media posts, and predicting user behavior.\n",
      "\n",
      "7. **Graphic Design**: Generative AI-powered graphic design tools can help businesses create high-quality visual content in a fraction of the time it would take to do so manually.\n",
      "\n",
      "8. **Video Content Creation**: Generative AI can be used to generate video thumbnails, titles, and descriptions that are more engaging and effective at driving views.\n",
      "\n",
      "9. **Predictive Maintenance**: Generative AI can be used to analyze machine sensor data and predict when maintenance needs to be performed in order to prevent equipment failure.\n",
      "\n",
      "10. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain management by predicting demand, managing inventory levels, and identifying potential bottlenecks.\n",
      "\n",
      "11. **Financial Analysis**: Generative AI can be used to analyze financial data and generate insights that help businesses make better informed investment decisions.\n",
      "\n",
      "12. **Human Resources Management**: Generative AI can be used to automate certain HR tasks such as resume screening, candidate matching, and performance predictions.\n",
      "\n",
      "13. **Cybersecurity Threat Detection**: Generative AI-powered systems can be designed to detect and respond to cybersecurity threats in real-time, helping businesses protect their networks and data from cyber attacks.\n",
      "\n",
      "14. **Medical Diagnosis**: Generative AI is being used in medicine to analyze medical images and diagnose diseases more accurately than human clinicians.\n",
      "\n",
      "15. **Accessibility Tools**: Generative AI can be used to create custom tools that help people with disabilities communicate more effectively or navigate complex environments.\n",
      "\n",
      "These are just a few examples of the many applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative solutions across various industries and use cases.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to provide clear definitions for neural networks, attention mechanisms, and transformers as they pertain to large language models (LLMs). Let's break each one down.\n",
      "\n",
      "Starting with neural networks. From what I remember, neural networks are computational models inspired by the human brain. They consist of layers that process data step by step. The input layer receives data, there are hidden layers where processing happens using weights and biases, and an output layer gives predictions or results. Each connection between neurons has a weight that's learned during training to adjust outputs based on inputs.\n",
      "\n",
      "Next, attention mechanisms. I've heard terms like self-attention in the context of transformers. Attention allows models to focus on relevant parts of the input when making decisions. It works by scoring different word pairs and selecting the most important ones, enabling efficient and accurate processing. This is used in tasks like machine translation where understanding context is crucial.\n",
      "\n",
      "Transformers are a type of neural network structure popularized by BERT models. They use self-attention instead of convolutional layers for processing sequential data like text. The transformer architecture involves token embeddings, positional embeddings, attention computation, and feed-forward networks. This design allows attending to all previous tokens simultaneously, handling long-range dependencies better than previous models.\n",
      "\n",
      "Putting it all together, I can explain each concept clearly, ensuring they're understandable even if someone isn't deeply familiar with the internals of LLMs.\n",
      "</think>\n",
      "\n",
      "### Neural Networks\n",
      "A neural network is a computational model that mimics the structure and function of biological neural networks. It consists of layers of interconnected nodes (neurons) that process information through weighted connections.\n",
      "\n",
      "1. **Input Layer**: Receives raw data or inputs.\n",
      "2. **Hidden Layers**: Perform computations and transformations on inputs using weights and biases, allowing detection of patterns.\n",
      "3. **Output Layer**: Provides predictions or results based on the processed input data.\n",
      "\n",
      "Neural networks are trained to adjust these parameters (weights and biases) through backpropagation to improve their performance. They can be used for various tasks such as classification, regression, and generation.\n",
      "\n",
      "---\n",
      "\n",
      "### Attention Mechanisms\n",
      "An attention mechanism is a process that allows models to focus on relevant parts of the input when generating an output or making decisions. It's crucial in transformer-based architectures but also appears in other models like CNNs.\n",
      "\n",
      "- **Self-attention**: The model examines its own inputs to weigh how much each part attends to others.\n",
      "  - **Query, Key, Value**: These are three vectors derived from the input embeddings that determine how features interact and connect across different positions or over time scales.\n",
      "  \n",
      "Example:\n",
      "In machine translation, attention helps focus on specific parts of the source sentence when translating a word in the target sentence.\n",
      "\n",
      "---\n",
      "\n",
      "### Transformers\n",
      "The transformer is an architecture introduced for processing sequential data (e.g., text) using self-attention mechanisms. It emerged as an alternative to traditional recurrent networks and has become pivotal in language modeling tasks.\n",
      "\n",
      "1. **Token Embeddings**: Convert input tokens into dense vector representations.\n",
      "2. **Positional Embeddings**: Add information about the position of each token in the sequence.\n",
      "3. **Self-Attention Mechanism**: Uses scaled dot-product attention to weigh importance across different tokens based on their relevance.\n",
      "4. **Feed-Forward Networks**: Process data through multiple linear transformations, allowing complex functions to be represented.\n",
      "\n",
      "The transformer handles both local and global dependencies effectively by attending simultaneously to all parts of the input sequence, making it highly efficient for capturing long-range relationships in text.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
